# 3月份文献阅读(Prompt tuning and Verbalizers)

整理人：陈皓_10205102429



## 1. Knowledgable Prompt Tuning

**论文链接**：[Knowledgeable Prompt-tuning: Incorporating Knowledge into Prompt Verbalizer for Text Classification](https://aclanthology.org/2022.acl-long.158.pdf)

**发表会议**：2022 ACL

**发表单位（院校）**：清华大学

**一作**：Shengding Hu

### 1.1 主体思想

本文主要针对prompt-tuning中的verbalizer部分进行修改，通过引入额外的知识扩展标签词空间，为了更好的利用知识利用PLM重新定义了扩展后的标签词空间。

### 1.2 模型架构

![1](image/1.png)

**备注说明**：

1. 标签词空间通过已经有的知识图谱被拓展，一个标签对应的词语增多了，拓宽了知识的广度。
2. 预训练语言模型在标签词上预测的概率会被最终转化成标签的概率，哪一个更高，则分类为哪一个标签。
3. 针对于广泛的知识源，词语经过了一定量的精细化（Refine），得出最终所需要运用的知识。
4. 由于人工设计的模板已被证明比自动学习出的模板更加有效，每个数据集使用了4个人工设计的模板，报告4个模板的评价结果和最佳结果
5. KPT始终优于PT，特别是在5-shot和10-shot实验中
6. 对于20-shot，认为标签实例的数量足以优化标签词的嵌入，使其远离原来的词嵌入，从而使知识丰富的语义，所以引入知识的verbalizer提供较少的帮助

**实验结果：**

**zero-shot**

![11](image/11.png)

**few-shot**

![12](image/12.png)

### 1.3 待改进之处

1. 用更精细化的方法从verbalizer中选择有用的标签词。（预先进行过实验，发现在agnews数据集上较少的知识嵌入也能够取得很好的效果）
2. 在模板构造和verbalizer设计方面用更好方法结合知识库和prompt-tuning
3. 如何构造好一个好的知识嵌入的verbalizer，以及对于verbalizer的功能和架构进行设计，可作为一个研究的方向。



## 2. Pattern-Exploiting Training(PET)

**论文链接**：[Exploiting Cloze Questions for Few Shot Text Classifification and Natural Language Inference](https://aclanthology.org/2021.eacl-main.20.pdf)

**发表会议**：2021 EACL

**发表单位（院校）**：慕尼黑大学信息和语言处理中心

**一作**：Timo Schick

### 1.1 主体思想

提出了PET的训练模式以及verbalizer的概念，对于prompt tuning用在分类问题中有着比较显著的意义。

当在小样本学习的领域，有task description存在的情况下，任务的解决会变得更加简单。

### 1.2 模型架构

![2](image/2.png)

该图表示的是PET工作的三个步骤：

1. 首先，对于每个模式，一个单独的 PLM 在一个小训练集 T 上进行微调。
2. 然后使用所有模型的集合来注释带有软标签的大型未标记数据集 D。
3. 最后，在软标记数据集上训练标准分类器。我们还设计了 iPET，这是 PET 的一种迭代变体，其中随着训练集大小的增加重复此过程。
<<<<<<< HEAD

**PVP**：一个(P,v)组成的元组对

P(x)是一个模式，将输入的句子包装。

![3](image/3.png)

![4](image/4.png)

v是一个Verbalizer，将分类问题中的类别映射到要填到空格的词当中（感觉通常上像是单射）。

如正例映射到“Yes”，负例映射到“No”

训练定义：定义一个 M(w∣Z) 表示给定带有一个[MASK]标记的序列 Z，语言模型可以在该[MASK]位置填入词 w∈L 的非归一化得分，即：(M是一个评分函数)

![5](image/5.png)

其次定义概率分布(类似于softmax的分布，最终转化成概率的问题）。

![6](image/6.png)

总的损失函数：

![7](image/7.png)

**对于给定的PVP，一个难题是如何确定哪一个PVP表现的好，因此需要走以下三步**：

1. 每一个PVP都在一个小的数据集上进行微调。
2. 将每一个预训练模型进行集成、对于每个预训练模型，分别对未标注的数据集 D 进行标注，此时获得的是soft-label，即给定一个输入 X，标签 l∈V 的概率得分：![8](image/8.png)
3. 在 Tc 使用标准的微调方法进行微调。微调之后的模型即作为最终的分类器

(有点像知识蒸馏)

**迭代方式的PEI（iPET）**：

![9](image/9.png)

**实验结果**：

![10](image/10.png)

### 1.3 待改进之处

这篇文献是2021年提出的，但感觉其中的一些方法在相关的数据规模上已经超过了2022年提出来的KPT
